{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOADDcv4YznGVHS9HxtZHp0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subuppaluru/RNN/blob/main/RNN_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ulLfMsV4HJHF"
      },
      "outputs": [],
      "source": [
        "# import all libraries\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "nlp=spacy.load(\"en\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "train=pd.read_csv(\"training.1600000.processed.noemoticon.csv\" , encoding= \"latin-1\")\n",
        "Y_train = train[train.columns[0]]\n",
        "X_train = train[train.columns[5]]"
      ],
      "metadata": {
        "id": "kY8VlpwOHQ58"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into test and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainset1x, trainset2x, trainset1y, trainset2y = train_test_split(X_train.values, Y_train.values, test_size=0.02,random_state=42 )\n",
        "trainset2y=pd.get_dummies(trainset2y)"
      ],
      "metadata": {
        "id": "WM-P35o4HedR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset1x.shape, trainset2x.shape, trainset1y.shape, trainset2y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhN2oYxTHnkg",
        "outputId": "2b714461-819d-446f-aedc-5fe6a95f26f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19599,) (400,) (19599,) (400, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove stopwords\n",
        "def stopwords(sentence):\n",
        "   new=[]\n",
        "   sentence=nlp(sentence)\n",
        "   for w in sentence:\n",
        "        if (w.is_stop == False) & (w.pos_ !=\"PUNCT\"):\n",
        "            new.append(w.string.strip())\n",
        "        c=\" \".join(str(x) for x in new)\n",
        "        return c"
      ],
      "metadata": {
        "id": "_-v8LnE6HzGP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to lemmatize the tweets\n",
        "def lemmatize(sentence):\n",
        "    sentence=nlp(sentence)\n",
        "    str=\"\"\n",
        "    for w in sentence:\n",
        "        str+=\" \"+w.lemma_\n",
        "    return nlp(str)"
      ],
      "metadata": {
        "id": "EGvH5y2tIBsX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the glove model\n",
        "def loadGloveModel(gloveFile):\n",
        "    print(\"Loading Glove Model\")\n",
        "    f = open(gloveFile,'r')\n",
        "    model = {}\n",
        "    for line in f:\n",
        "        splitLine = line.split()\n",
        "        word = splitLine[0]\n",
        "        embedding = [float(val) for val in splitLine[1:]]\n",
        "        model[word] = embedding\n",
        "    print (\"Done.\"),len(model),(\" words loaded!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "lfyMBkg0IJ5I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the glove model\n",
        "#https://www.kaggle.com/fullmetal26/glovetwitter27b100dtxt\n",
        "model=loadGloveModel(\"glove.twitter.27B.200d.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzQiv0lsINlO",
        "outputId": "09526cad-74c1-4aaf-be5b-0bc4d06b15de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Glove Model\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorising the sentences\n",
        "def sent_vectorizer(sent, model):\n",
        "    sent_vec = np.zeros(200)\n",
        "    numw = 0\n",
        "    for w in sent.split():\n",
        "        try:\n",
        "            sent_vec = np.add(sent_vec, model[str(w)])\n",
        "            numw+=1\n",
        "        except:\n",
        "            pass\n",
        "    return sent_vec"
      ],
      "metadata": {
        "id": "SER3xncWI1PO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain a clean vector\n",
        "cleanvector=[]\n",
        "for i in range(trainset2x.shape[0]):\n",
        "    document=trainset2x[i]\n",
        "    document=document.lower()\n",
        "    document=lemmatize(document)\n",
        "    document=str(document)\n",
        "    cleanvector.append(sent_vectorizer(document,model))"
      ],
      "metadata": {
        "id": "_sGtv-XOI5og"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the input and output in proper shape\n",
        "cleanvector=np.array(cleanvector)\n",
        "cleanvector =cleanvector.reshape(len(cleanvector),200,1)\n"
      ],
      "metadata": {
        "id": "wZyITPkjI9in"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the sequences\n",
        "tokenizer = Tokenizer(num_words=16000)\n",
        "tokenizer.fit_on_texts(trainset2x)\n",
        "sequences = tokenizer.texts_to_sequences(trainset2x)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "data = pad_sequences(sequences, maxlen=15, padding=\"post\")\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st1ZZ08KJALe",
        "outputId": "7fa19432-9755-43f0-c09a-690e76970079"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1873 unique tokens.\n",
            "(400, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape the data and preparing to train\n",
        "data=data.reshape(len(cleanvector),15,1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainx, validx, trainy, validy = train_test_split(data, trainset2y, test_size=0.3,random_state=42 )"
      ],
      "metadata": {
        "id": "YuPTFLs4JD4P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the number of words\n",
        "nb_words=len(tokenizer.word_index)+1\n",
        "print(nb_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4SbQ_NgJIFm",
        "outputId": "887e6a58-bcd9-4925-8492-b45a37f28a2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain theembedding matrix\n",
        "embedding_matrix = np.zeros((nb_words, 200))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = model.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VorSok0JK2X",
        "outputId": "9f1aac02-aef3-4828-ead4-873a1fc77cc7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null word embeddings: 628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainy=np.array(trainy)\n",
        "validy=np.array(validy)"
      ],
      "metadata": {
        "id": "kUQjVqD4JOYA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainy.shape,validy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-y98o5dK-ES",
        "outputId": "66808bc6-66bc-4f63-e681-e834c9894506"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(280, 2) (120, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "BtESiDp0JRlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#building a simple RNN model\n",
        "def modelbuild():\n",
        "    model = Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=(15,1)))\n",
        "    keras.layers.embeddings.Embedding(nb_words, 15, weights=[embedding_matrix], input_length=15,\n",
        "    trainable=False)\n",
        " \n",
        "    model.add(keras.layers.recurrent.SimpleRNN(units = 100, activation='relu',\n",
        "    use_bias=True))\n",
        "    model.add(keras.layers.Dense(units=1000, input_dim = 2000, activation='sigmoid'))\n",
        "    model.add(keras.layers.Dense(units=500, input_dim=1000, activation='relu'))\n",
        "    model.add(keras.layers.Dense(units=2, input_dim=500,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "sduFkP0lJSrm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling the model\n",
        "finalmodel = modelbuild()\n",
        "finalmodel.fit(trainx, trainy, epochs=100, batch_size=120,validation_data=(validx,validy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYQwPuEUJWSp",
        "outputId": "e35bba1a-c143-4410-cd31-c813deb2ce59"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 135ms/step - loss: 2.3412 - accuracy: 0.4429 - val_loss: 1.9398 - val_accuracy: 0.5083\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.5421 - accuracy: 0.5393 - val_loss: 0.9194 - val_accuracy: 0.5167\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9893 - accuracy: 0.4857 - val_loss: 0.8191 - val_accuracy: 0.5083\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.6949 - accuracy: 0.5536 - val_loss: 0.8827 - val_accuracy: 0.5083\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.7863 - accuracy: 0.5357 - val_loss: 0.7174 - val_accuracy: 0.4833\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6593 - accuracy: 0.6000 - val_loss: 0.7966 - val_accuracy: 0.5083\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.6881 - accuracy: 0.5286 - val_loss: 0.7264 - val_accuracy: 0.4583\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.6194 - accuracy: 0.6286 - val_loss: 0.7494 - val_accuracy: 0.5083\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6098 - accuracy: 0.6214 - val_loss: 0.7290 - val_accuracy: 0.4750\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.5837 - accuracy: 0.7429 - val_loss: 0.7387 - val_accuracy: 0.5333\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.5785 - accuracy: 0.7250 - val_loss: 0.7370 - val_accuracy: 0.5250\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.5568 - accuracy: 0.7357 - val_loss: 0.7541 - val_accuracy: 0.4833\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.5521 - accuracy: 0.7214 - val_loss: 0.7518 - val_accuracy: 0.4583\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.5270 - accuracy: 0.8179 - val_loss: 0.7757 - val_accuracy: 0.5583\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.5286 - accuracy: 0.7679 - val_loss: 0.7683 - val_accuracy: 0.4667\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.5032 - accuracy: 0.7679 - val_loss: 0.7924 - val_accuracy: 0.4833\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.5052 - accuracy: 0.7643 - val_loss: 0.7871 - val_accuracy: 0.5333\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.4811 - accuracy: 0.8036 - val_loss: 0.7797 - val_accuracy: 0.5250\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4650 - accuracy: 0.8071 - val_loss: 0.7925 - val_accuracy: 0.5083\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.4417 - accuracy: 0.8214 - val_loss: 0.8064 - val_accuracy: 0.5083\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4256 - accuracy: 0.8357 - val_loss: 0.8158 - val_accuracy: 0.4833\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.4066 - accuracy: 0.8250 - val_loss: 0.8337 - val_accuracy: 0.5250\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.3905 - accuracy: 0.8464 - val_loss: 0.8443 - val_accuracy: 0.5750\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.3741 - accuracy: 0.8429 - val_loss: 0.8553 - val_accuracy: 0.4917\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3610 - accuracy: 0.8786 - val_loss: 0.8890 - val_accuracy: 0.5083\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.3360 - accuracy: 0.8857 - val_loss: 0.9023 - val_accuracy: 0.5167\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3324 - accuracy: 0.8643 - val_loss: 0.9306 - val_accuracy: 0.4833\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3119 - accuracy: 0.8964 - val_loss: 0.9648 - val_accuracy: 0.4917\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.3123 - accuracy: 0.8786 - val_loss: 1.0045 - val_accuracy: 0.4750\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2844 - accuracy: 0.8929 - val_loss: 1.0451 - val_accuracy: 0.4583\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2572 - accuracy: 0.9250 - val_loss: 1.0642 - val_accuracy: 0.4917\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2400 - accuracy: 0.9107 - val_loss: 1.1099 - val_accuracy: 0.5500\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2492 - accuracy: 0.9036 - val_loss: 1.1008 - val_accuracy: 0.4917\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2431 - accuracy: 0.9000 - val_loss: 1.1406 - val_accuracy: 0.4750\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2416 - accuracy: 0.9036 - val_loss: 1.2166 - val_accuracy: 0.5333\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2116 - accuracy: 0.9143 - val_loss: 1.2024 - val_accuracy: 0.4833\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2227 - accuracy: 0.8964 - val_loss: 1.2392 - val_accuracy: 0.5250\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1894 - accuracy: 0.9393 - val_loss: 1.2409 - val_accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1841 - accuracy: 0.9214 - val_loss: 1.1987 - val_accuracy: 0.5417\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1660 - accuracy: 0.9464 - val_loss: 1.2572 - val_accuracy: 0.5917\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1836 - accuracy: 0.9286 - val_loss: 1.2958 - val_accuracy: 0.5250\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1789 - accuracy: 0.9357 - val_loss: 1.3538 - val_accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1820 - accuracy: 0.9393 - val_loss: 1.4504 - val_accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2049 - accuracy: 0.9214 - val_loss: 1.3240 - val_accuracy: 0.5333\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1918 - accuracy: 0.9179 - val_loss: 1.3664 - val_accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1535 - accuracy: 0.9500 - val_loss: 1.4311 - val_accuracy: 0.5250\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1585 - accuracy: 0.9429 - val_loss: 1.4174 - val_accuracy: 0.5333\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1379 - accuracy: 0.9393 - val_loss: 1.5154 - val_accuracy: 0.5333\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1296 - accuracy: 0.9536 - val_loss: 1.5945 - val_accuracy: 0.5333\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1219 - accuracy: 0.9750 - val_loss: 1.6272 - val_accuracy: 0.5250\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1220 - accuracy: 0.9643 - val_loss: 1.6414 - val_accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1212 - accuracy: 0.9679 - val_loss: 1.7042 - val_accuracy: 0.5250\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1232 - accuracy: 0.9679 - val_loss: 1.7187 - val_accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1651 - accuracy: 0.9429 - val_loss: 1.6015 - val_accuracy: 0.5250\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1471 - accuracy: 0.9429 - val_loss: 1.6314 - val_accuracy: 0.4917\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1723 - accuracy: 0.9393 - val_loss: 1.5605 - val_accuracy: 0.5250\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1637 - accuracy: 0.9250 - val_loss: 1.6150 - val_accuracy: 0.5500\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1458 - accuracy: 0.9393 - val_loss: 1.6599 - val_accuracy: 0.5083\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1312 - accuracy: 0.9464 - val_loss: 1.6760 - val_accuracy: 0.5083\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1230 - accuracy: 0.9607 - val_loss: 1.6704 - val_accuracy: 0.5417\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1197 - accuracy: 0.9571 - val_loss: 1.7589 - val_accuracy: 0.5500\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1265 - accuracy: 0.9500 - val_loss: 1.7884 - val_accuracy: 0.5333\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1355 - accuracy: 0.9357 - val_loss: 1.7716 - val_accuracy: 0.5333\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1220 - accuracy: 0.9536 - val_loss: 1.8559 - val_accuracy: 0.5500\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1163 - accuracy: 0.9571 - val_loss: 1.9024 - val_accuracy: 0.5333\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1349 - accuracy: 0.9321 - val_loss: 1.7907 - val_accuracy: 0.5500\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1150 - accuracy: 0.9500 - val_loss: 1.7222 - val_accuracy: 0.5500\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1182 - accuracy: 0.9464 - val_loss: 1.7389 - val_accuracy: 0.5500\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1207 - accuracy: 0.9679 - val_loss: 1.7490 - val_accuracy: 0.5500\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1056 - accuracy: 0.9571 - val_loss: 1.8634 - val_accuracy: 0.5083\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1249 - accuracy: 0.9321 - val_loss: 1.9162 - val_accuracy: 0.5250\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1068 - accuracy: 0.9571 - val_loss: 1.9818 - val_accuracy: 0.5417\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1030 - accuracy: 0.9714 - val_loss: 2.0217 - val_accuracy: 0.5167\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1183 - accuracy: 0.9464 - val_loss: 2.0498 - val_accuracy: 0.5333\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1216 - accuracy: 0.9500 - val_loss: 2.0547 - val_accuracy: 0.5500\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1635 - accuracy: 0.9393 - val_loss: 2.0086 - val_accuracy: 0.5500\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1174 - accuracy: 0.9429 - val_loss: 1.8440 - val_accuracy: 0.5750\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1479 - accuracy: 0.9357 - val_loss: 1.7301 - val_accuracy: 0.5333\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1930 - accuracy: 0.9107 - val_loss: 1.8445 - val_accuracy: 0.5917\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1805 - accuracy: 0.9179 - val_loss: 1.8813 - val_accuracy: 0.5500\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2628 - accuracy: 0.9071 - val_loss: 1.9263 - val_accuracy: 0.5500\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.3297 - accuracy: 0.8536 - val_loss: 1.8423 - val_accuracy: 0.5167\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.4204 - accuracy: 0.8071 - val_loss: 1.6461 - val_accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3608 - accuracy: 0.8357 - val_loss: 1.5670 - val_accuracy: 0.4750\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2644 - accuracy: 0.8750 - val_loss: 1.6658 - val_accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2179 - accuracy: 0.9071 - val_loss: 1.7083 - val_accuracy: 0.5250\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2912 - accuracy: 0.8571 - val_loss: 1.5108 - val_accuracy: 0.5333\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2372 - accuracy: 0.8821 - val_loss: 1.4956 - val_accuracy: 0.5333\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1998 - accuracy: 0.9071 - val_loss: 1.6189 - val_accuracy: 0.4917\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1716 - accuracy: 0.9143 - val_loss: 1.7238 - val_accuracy: 0.4833\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1586 - accuracy: 0.9321 - val_loss: 1.7882 - val_accuracy: 0.5333\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1780 - accuracy: 0.9107 - val_loss: 1.7397 - val_accuracy: 0.5167\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.1510 - accuracy: 0.9357 - val_loss: 1.7272 - val_accuracy: 0.5333\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1251 - accuracy: 0.9536 - val_loss: 1.7509 - val_accuracy: 0.5333\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1154 - accuracy: 0.9679 - val_loss: 1.7419 - val_accuracy: 0.5333\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1272 - accuracy: 0.9321 - val_loss: 1.7497 - val_accuracy: 0.5333\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1050 - accuracy: 0.9643 - val_loss: 1.8176 - val_accuracy: 0.5583\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0966 - accuracy: 0.9679 - val_loss: 1.8622 - val_accuracy: 0.5250\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1005 - accuracy: 0.9607 - val_loss: 1.9247 - val_accuracy: 0.5417\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0883 - accuracy: 0.9607 - val_loss: 2.0078 - val_accuracy: 0.5167\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89914b9950>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}